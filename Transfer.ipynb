{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from time import time\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(12)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import glob\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_dataset = \"Dataset/WISDM/WISDM_ar_v1.1/a.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x-axis</th>\n",
       "      <th>y-axis</th>\n",
       "      <th>z-axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49105962326000</td>\n",
       "      <td>-0.694638</td>\n",
       "      <td>12.680544</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106062271000</td>\n",
       "      <td>5.012288</td>\n",
       "      <td>11.264028</td>\n",
       "      <td>0.953424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106112167000</td>\n",
       "      <td>4.903325</td>\n",
       "      <td>10.882658</td>\n",
       "      <td>-0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106222305000</td>\n",
       "      <td>-0.612916</td>\n",
       "      <td>18.496431</td>\n",
       "      <td>3.023717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106332290000</td>\n",
       "      <td>-1.184970</td>\n",
       "      <td>12.108489</td>\n",
       "      <td>7.205164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106442306000</td>\n",
       "      <td>1.375655</td>\n",
       "      <td>-2.492524</td>\n",
       "      <td>-6.510526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106542312000</td>\n",
       "      <td>-0.612916</td>\n",
       "      <td>10.569390</td>\n",
       "      <td>5.706926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106652389000</td>\n",
       "      <td>-0.503953</td>\n",
       "      <td>13.947236</td>\n",
       "      <td>7.055340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106762313000</td>\n",
       "      <td>-8.430995</td>\n",
       "      <td>11.413852</td>\n",
       "      <td>5.134871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106872299000</td>\n",
       "      <td>0.953424</td>\n",
       "      <td>1.375655</td>\n",
       "      <td>1.648062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106982315000</td>\n",
       "      <td>-8.199450</td>\n",
       "      <td>19.572440</td>\n",
       "      <td>2.724070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107092330000</td>\n",
       "      <td>1.416516</td>\n",
       "      <td>5.788648</td>\n",
       "      <td>2.982856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107202316000</td>\n",
       "      <td>-1.879608</td>\n",
       "      <td>-2.982856</td>\n",
       "      <td>-0.299648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107312332000</td>\n",
       "      <td>-6.129157</td>\n",
       "      <td>6.851035</td>\n",
       "      <td>-8.158588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107422348000</td>\n",
       "      <td>5.829509</td>\n",
       "      <td>18.006100</td>\n",
       "      <td>8.539958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107522293000</td>\n",
       "      <td>6.278980</td>\n",
       "      <td>2.982856</td>\n",
       "      <td>2.914754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107632339000</td>\n",
       "      <td>-1.566340</td>\n",
       "      <td>8.308413</td>\n",
       "      <td>-1.457377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107742355000</td>\n",
       "      <td>3.527670</td>\n",
       "      <td>13.593107</td>\n",
       "      <td>9.425281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107852340000</td>\n",
       "      <td>-2.029432</td>\n",
       "      <td>-5.706926</td>\n",
       "      <td>-10.188020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107962326000</td>\n",
       "      <td>2.764931</td>\n",
       "      <td>10.337844</td>\n",
       "      <td>-9.724928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108062271000</td>\n",
       "      <td>3.568531</td>\n",
       "      <td>13.674830</td>\n",
       "      <td>1.539099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108172348000</td>\n",
       "      <td>-0.503953</td>\n",
       "      <td>3.868179</td>\n",
       "      <td>3.718355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108272262000</td>\n",
       "      <td>-2.301839</td>\n",
       "      <td>1.688923</td>\n",
       "      <td>0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108382370000</td>\n",
       "      <td>-3.568531</td>\n",
       "      <td>19.572440</td>\n",
       "      <td>6.510526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108492294000</td>\n",
       "      <td>-0.803601</td>\n",
       "      <td>-3.296124</td>\n",
       "      <td>-4.630918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108602371000</td>\n",
       "      <td>0.503953</td>\n",
       "      <td>10.841797</td>\n",
       "      <td>13.525005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108702285000</td>\n",
       "      <td>5.706926</td>\n",
       "      <td>15.595298</td>\n",
       "      <td>6.170018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108812332000</td>\n",
       "      <td>-8.662541</td>\n",
       "      <td>7.273266</td>\n",
       "      <td>4.018003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108922378000</td>\n",
       "      <td>-1.334794</td>\n",
       "      <td>1.225831</td>\n",
       "      <td>2.369940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49109022293000</td>\n",
       "      <td>-4.590057</td>\n",
       "      <td>19.572440</td>\n",
       "      <td>4.712640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098174</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622091524000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.270000</td>\n",
       "      <td>2.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098175</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622131471000</td>\n",
       "      <td>8.960000</td>\n",
       "      <td>-1.310000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098176</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622171541000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.330000</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098177</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622211580000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>-1.420000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098178</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622291475000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>-1.380000</td>\n",
       "      <td>2.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098179</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622331483000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.310000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098180</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622371522000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.140000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098181</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622451479000</td>\n",
       "      <td>8.960000</td>\n",
       "      <td>-1.120000</td>\n",
       "      <td>2.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098182</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622491487000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>-1.120000</td>\n",
       "      <td>2.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098183</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622531465000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>-1.120000</td>\n",
       "      <td>2.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098184</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622571443000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>-1.140000</td>\n",
       "      <td>2.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098185</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622611635000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.230000</td>\n",
       "      <td>2.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098186</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622691469000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.230000</td>\n",
       "      <td>2.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098187</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622731477000</td>\n",
       "      <td>8.770000</td>\n",
       "      <td>-1.330000</td>\n",
       "      <td>2.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098188</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622771486000</td>\n",
       "      <td>8.960000</td>\n",
       "      <td>-1.380000</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098189</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622851472000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>2.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098190</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622891511000</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>-1.650000</td>\n",
       "      <td>2.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098191</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622931490000</td>\n",
       "      <td>8.960000</td>\n",
       "      <td>-1.460000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098192</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622971498000</td>\n",
       "      <td>9.230000</td>\n",
       "      <td>-1.460000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098193</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623051485000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>-1.230000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098194</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623091524000</td>\n",
       "      <td>8.540000</td>\n",
       "      <td>-1.310000</td>\n",
       "      <td>2.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098195</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623131471000</td>\n",
       "      <td>8.660000</td>\n",
       "      <td>-1.310000</td>\n",
       "      <td>2.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098196</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623172578000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>-1.270000</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098197</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623251466000</td>\n",
       "      <td>9.110000</td>\n",
       "      <td>-1.380000</td>\n",
       "      <td>1.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098198</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623291475000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098199</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623331483000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.570000</td>\n",
       "      <td>1.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098200</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623371431000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>-1.460000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098201</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623411592000</td>\n",
       "      <td>9.080000</td>\n",
       "      <td>-1.380000</td>\n",
       "      <td>1.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098202</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623491487000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.460000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098203</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623531465000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>-1.330000</td>\n",
       "      <td>1.610000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1098204 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user activity        timestamp    x-axis     y-axis     z-axis\n",
       "0          33  Jogging   49105962326000 -0.694638  12.680544   0.503953\n",
       "1          33  Jogging   49106062271000  5.012288  11.264028   0.953424\n",
       "2          33  Jogging   49106112167000  4.903325  10.882658  -0.081722\n",
       "3          33  Jogging   49106222305000 -0.612916  18.496431   3.023717\n",
       "4          33  Jogging   49106332290000 -1.184970  12.108489   7.205164\n",
       "5          33  Jogging   49106442306000  1.375655  -2.492524  -6.510526\n",
       "6          33  Jogging   49106542312000 -0.612916  10.569390   5.706926\n",
       "7          33  Jogging   49106652389000 -0.503953  13.947236   7.055340\n",
       "8          33  Jogging   49106762313000 -8.430995  11.413852   5.134871\n",
       "9          33  Jogging   49106872299000  0.953424   1.375655   1.648062\n",
       "10         33  Jogging   49106982315000 -8.199450  19.572440   2.724070\n",
       "11         33  Jogging   49107092330000  1.416516   5.788648   2.982856\n",
       "12         33  Jogging   49107202316000 -1.879608  -2.982856  -0.299648\n",
       "13         33  Jogging   49107312332000 -6.129157   6.851035  -8.158588\n",
       "14         33  Jogging   49107422348000  5.829509  18.006100   8.539958\n",
       "15         33  Jogging   49107522293000  6.278980   2.982856   2.914754\n",
       "16         33  Jogging   49107632339000 -1.566340   8.308413  -1.457377\n",
       "17         33  Jogging   49107742355000  3.527670  13.593107   9.425281\n",
       "18         33  Jogging   49107852340000 -2.029432  -5.706926 -10.188020\n",
       "19         33  Jogging   49107962326000  2.764931  10.337844  -9.724928\n",
       "20         33  Jogging   49108062271000  3.568531  13.674830   1.539099\n",
       "21         33  Jogging   49108172348000 -0.503953   3.868179   3.718355\n",
       "22         33  Jogging   49108272262000 -2.301839   1.688923   0.081722\n",
       "23         33  Jogging   49108382370000 -3.568531  19.572440   6.510526\n",
       "24         33  Jogging   49108492294000 -0.803601  -3.296124  -4.630918\n",
       "25         33  Jogging   49108602371000  0.503953  10.841797  13.525005\n",
       "26         33  Jogging   49108702285000  5.706926  15.595298   6.170018\n",
       "27         33  Jogging   49108812332000 -8.662541   7.273266   4.018003\n",
       "28         33  Jogging   49108922378000 -1.334794   1.225831   2.369940\n",
       "29         33  Jogging   49109022293000 -4.590057  19.572440   4.712640\n",
       "...       ...      ...              ...       ...        ...        ...\n",
       "1098174    19  Sitting  131622091524000  8.920000  -1.270000   2.220000\n",
       "1098175    19  Sitting  131622131471000  8.960000  -1.310000   2.260000\n",
       "1098176    19  Sitting  131622171541000  8.920000  -1.330000   2.180000\n",
       "1098177    19  Sitting  131622211580000  8.850000  -1.420000   2.260000\n",
       "1098178    19  Sitting  131622291475000  8.880000  -1.380000   2.410000\n",
       "1098179    19  Sitting  131622331483000  8.920000  -1.310000   2.300000\n",
       "1098180    19  Sitting  131622371522000  8.920000  -1.140000   2.260000\n",
       "1098181    19  Sitting  131622451479000  8.960000  -1.120000   2.340000\n",
       "1098182    19  Sitting  131622491487000  9.040000  -1.120000   2.410000\n",
       "1098183    19  Sitting  131622531465000  8.880000  -1.120000   2.370000\n",
       "1098184    19  Sitting  131622571443000  8.880000  -1.140000   2.370000\n",
       "1098185    19  Sitting  131622611635000  8.920000  -1.230000   2.450000\n",
       "1098186    19  Sitting  131622691469000  8.920000  -1.230000   2.450000\n",
       "1098187    19  Sitting  131622731477000  8.770000  -1.330000   2.530000\n",
       "1098188    19  Sitting  131622771486000  8.960000  -1.380000   2.600000\n",
       "1098189    19  Sitting  131622851472000  8.500000  -1.500000   2.560000\n",
       "1098190    19  Sitting  131622891511000  8.270000  -1.650000   2.110000\n",
       "1098191    19  Sitting  131622931490000  8.960000  -1.460000   2.300000\n",
       "1098192    19  Sitting  131622971498000  9.230000  -1.460000   2.260000\n",
       "1098193    19  Sitting  131623051485000  8.850000  -1.230000   2.260000\n",
       "1098194    19  Sitting  131623091524000  8.540000  -1.310000   2.490000\n",
       "1098195    19  Sitting  131623131471000  8.660000  -1.310000   2.370000\n",
       "1098196    19  Sitting  131623172578000  8.850000  -1.270000   2.180000\n",
       "1098197    19  Sitting  131623251466000  9.110000  -1.380000   1.950000\n",
       "1098198    19  Sitting  131623291475000  9.000000  -1.500000   1.800000\n",
       "1098199    19  Sitting  131623331483000  9.000000  -1.570000   1.690000\n",
       "1098200    19  Sitting  131623371431000  9.040000  -1.460000   1.730000\n",
       "1098201    19  Sitting  131623411592000  9.080000  -1.380000   1.690000\n",
       "1098202    19  Sitting  131623491487000  9.000000  -1.460000   1.730000\n",
       "1098203    19  Sitting  131623531465000  8.880000  -1.330000   1.610000\n",
       "\n",
       "[1098204 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['user','activity','timestamp', 'x-axis', 'y-axis', 'z-axis']\n",
    "df = pd.read_csv(path_dataset, header = None, names = columns )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "user         0\n",
      "activity     0\n",
      "timestamp    0\n",
      "x-axis       0\n",
      "y-axis       0\n",
      "z-axis       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fifamd\\Anaconda3\\envs\\tf\\lib\\site-packages\\scipy\\stats\\stats.py:253: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "N_TIME_STEPS = 200\n",
    "N_FEATURES = 3\n",
    "step = 20\n",
    "segments = []\n",
    "labels = []\n",
    "for i in range(0, len(df) - N_TIME_STEPS, step):\n",
    "    xs = df['x-axis'].values[i: i + N_TIME_STEPS]\n",
    "    ys = df['y-axis'].values[i: i + N_TIME_STEPS]\n",
    "    zs = df['z-axis'].values[i: i + N_TIME_STEPS]\n",
    "    label = stats.mode(df['activity'][i: i + N_TIME_STEPS])[0][0]\n",
    "    segments.append([xs, ys, zs])\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)\n",
    "labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reshaped_segments, labels, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense,LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from numpy.random import seed\n",
    "seed(12)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score_metric(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, \"int32\")\n",
    "    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n",
    "    y_correct = y_true * y_pred\n",
    "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
    "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
    "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
    "    precision = sum_correct / sum_pred\n",
    "    recall = sum_correct / sum_true\n",
    "    f_score = 5 * precision * recall / (4 * precision + recall)\n",
    "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
    "    return tf.reduce_mean(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43920, 200, 3)\n",
      "(43920, 6)\n",
      "(54901, 200, 3)\n",
      "200 3\n",
      "[[ 0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.]\n",
      " ..., \n",
      " [ 0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.]\n",
      " [ 1.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(reshaped_segments.shape)\n",
    "numOfRows = reshaped_segments.shape[1]\n",
    "numOfColumns = reshaped_segments.shape[2]\n",
    "filters = 128\n",
    "Epochs = 10\n",
    "batchSize = 10\n",
    "num_class = 6\n",
    "print(numOfRows , numOfColumns)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-db7dc4348638>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0my_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m43920\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "y_train = np.reshape(y_train,(43920,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TCNN():\n",
    "    base_model1 = Input(shape=(numOfRows,numOfColumns))\n",
    "    base_model = Conv1D(filters,(15),activation = 'relu')(base_model1)\n",
    "    base_model = MaxPooling1D(pool_size=4)(base_model)\n",
    "    base_model = Conv1D(filters,(15), activation = 'relu')(base_model)\n",
    "    base_model = MaxPooling1D(pool_size=5)(base_model)\n",
    "\n",
    "    base_model = LSTM(128)(base_model)\n",
    "\n",
    "    base_model = Dense(256)(base_model)\n",
    "    base_model = Dropout(0.2)(base_model)\n",
    "    base_model = Dense(6 ,activation=\"softmax\")(base_model)\n",
    "    model = Model(inputs=[base_model1], outputs=base_model)\n",
    "    adam = optimizers.Adam(lr = 0.001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 200, 3)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 186, 128)          5888      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 46, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 32, 128)           245888    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 1542      \n",
      "=================================================================\n",
      "Total params: 417,926\n",
      "Trainable params: 417,926\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "43920/43920 [==============================] - 80s 2ms/step - loss: 0.3128 - acc: 0.8844\n",
      "Epoch 2/10\n",
      "   64/43920 [..............................] - ETA: 1:26 - loss: 0.2178 - acc: 0.8906"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fifamd\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:406: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "C:\\Users\\fifamd\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:497: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "C:\\Users\\fifamd\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:898: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43920/43920 [==============================] - 78s 2ms/step - loss: 0.1553 - acc: 0.9467\n",
      "Epoch 3/10\n",
      "43920/43920 [==============================] - 76s 2ms/step - loss: 0.1157 - acc: 0.9612\n",
      "Epoch 4/10\n",
      "43920/43920 [==============================] - 77s 2ms/step - loss: 0.1015 - acc: 0.9654\n",
      "Epoch 5/10\n",
      "43920/43920 [==============================] - 78s 2ms/step - loss: 0.0816 - acc: 0.9717\n",
      "Epoch 6/10\n",
      "43920/43920 [==============================] - 77s 2ms/step - loss: 0.0730 - acc: 0.9753\n",
      "Epoch 7/10\n",
      "43920/43920 [==============================] - 78s 2ms/step - loss: 0.0680 - acc: 0.9774\n",
      "Epoch 8/10\n",
      "43920/43920 [==============================] - 77s 2ms/step - loss: 0.0653 - acc: 0.9778\n",
      "Epoch 9/10\n",
      "43920/43920 [==============================] - 76s 2ms/step - loss: 0.0629 - acc: 0.9785\n",
      "Epoch 10/10\n",
      "43920/43920 [==============================] - 80s 2ms/step - loss: 0.0596 - acc: 0.9806\n"
     ]
    }
   ],
   "source": [
    "m = TCNN()\n",
    "m.summary()\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
    "                                verbose=1, cooldown=5, min_lr=0)\n",
    "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=20, verbose=0, mode='max')\n",
    "\n",
    "model_1_path = \"./model/model_1/{}.h5\".format(\"model_1\")\n",
    "checkpoint = ModelCheckpoint(model_1_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
    "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
    "\n",
    "history = m.fit(X_train,y_train,epochs = Epochs, callbacks=callbacks_list, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.save_weights(\"./model/model_1.2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[[-0.08251053,  0.00512579, -0.04972309, ..., -0.11930908,\n",
      "          0.10253114, -0.11863396],\n",
      "        [-0.12347891,  0.03392795,  0.01903475, ..., -0.02300153,\n",
      "         -0.16131341, -0.17577523],\n",
      "        [ 0.02494622, -0.00483196, -0.04243604, ...,  0.04696309,\n",
      "         -0.10071559, -0.11098851]],\n",
      "\n",
      "       [[ 0.11216159, -0.02476394, -0.05713003, ...,  0.03858734,\n",
      "          0.00717816,  0.06111021],\n",
      "        [-0.195917  , -0.03960482, -0.03077825, ..., -0.06645834,\n",
      "          0.07262053, -0.00341955],\n",
      "        [-0.0092715 , -0.12777041, -0.05769717, ..., -0.17838943,\n",
      "         -0.22541054, -0.10149846]],\n",
      "\n",
      "       [[-0.08551205, -0.15963791, -0.05136813, ..., -0.10585863,\n",
      "          0.06197259,  0.07183219],\n",
      "        [ 0.01129385, -0.1321162 , -0.07725766, ...,  0.09558994,\n",
      "          0.02372855,  0.04819582],\n",
      "        [ 0.04580235,  0.04125176, -0.11423775, ...,  0.15815488,\n",
      "          0.21372306,  0.03404731]],\n",
      "\n",
      "       ..., \n",
      "       [[-0.08390899, -0.007429  ,  0.02613281, ...,  0.00673483,\n",
      "         -0.02133119, -0.07153547],\n",
      "        [-0.01493344,  0.01720519, -0.09962685, ..., -0.17413285,\n",
      "         -0.09566123, -0.03694484],\n",
      "        [ 0.0374826 , -0.06457024, -0.08242995, ..., -0.12910394,\n",
      "          0.03508959,  0.01794716]],\n",
      "\n",
      "       [[-0.00969937, -0.19128601, -0.05257911, ...,  0.02973745,\n",
      "          0.00683973,  0.09243379],\n",
      "        [-0.01222954, -0.02994792,  0.00876726, ...,  0.20500046,\n",
      "         -0.00576179,  0.08194327],\n",
      "        [-0.03354622,  0.07475904,  0.02251875, ...,  0.03670158,\n",
      "         -0.08019882,  0.05638225]],\n",
      "\n",
      "       [[ 0.02440387, -0.005692  , -0.03314412, ..., -0.07167333,\n",
      "          0.02075563, -0.08914733],\n",
      "        [ 0.01425772, -0.00496557, -0.0648463 , ..., -0.17628145,\n",
      "          0.07801005, -0.11562197],\n",
      "        [-0.05557524,  0.15671358, -0.06719548, ..., -0.07713908,\n",
      "         -0.02381887,  0.02344588]]], dtype=float32), array([-0.74751347, -0.25967675, -0.51770139, -0.84487933, -0.45612782,\n",
      "       -0.37855741, -0.63382298, -0.61736423, -0.9297753 , -0.75145441,\n",
      "       -0.77159989, -0.88707954, -0.61586332, -0.54254341, -0.30597064,\n",
      "       -0.95974737, -0.66129953, -0.76392549, -0.35144338, -0.70763749,\n",
      "       -0.27882507, -0.73316705, -0.65559107, -0.68507409,  0.24935976,\n",
      "       -0.80058378, -0.72820234, -0.75562918, -0.52789551, -0.87602192,\n",
      "       -0.22238934,  0.06694593, -0.55321032, -0.32127661, -0.41669592,\n",
      "       -0.59118927, -0.62372404, -0.65251565, -0.6441111 , -0.83738333,\n",
      "       -0.71298808, -0.51058632, -0.09225871, -0.70845294, -0.81564271,\n",
      "       -0.70781505, -0.34494069, -0.63508719, -0.64911306, -0.53314751,\n",
      "       -0.75962639, -0.53298771, -0.8030194 , -0.611453  , -0.10360105,\n",
      "       -0.55936992, -0.70836759, -0.28919515, -0.2660833 , -0.66319436,\n",
      "        0.03423814, -0.20132311, -0.50932491, -0.39068109, -0.28412467,\n",
      "       -0.14828263, -0.92124188, -0.34574595, -0.23995517, -0.25517616,\n",
      "       -0.24137275, -0.20395663, -0.58224314, -0.30097657, -0.10187504,\n",
      "       -0.56812418, -0.81960696, -0.2164873 , -0.61449856, -0.71502757,\n",
      "       -0.40129614, -0.28416833, -0.881396  , -0.57968819, -0.49701825,\n",
      "       -0.77735955, -0.89787012, -0.78071398, -0.85395557, -0.67214173,\n",
      "       -0.65042388, -0.63362712, -0.70180756, -0.86297673, -0.4879387 ,\n",
      "       -0.67081034, -0.78978688, -0.67542017, -0.60779846,  0.20067751,\n",
      "       -0.86486816, -0.65069968, -0.56113893, -0.64858884,  0.19934382,\n",
      "       -0.77662206, -0.42818829, -0.14809678, -0.62557358, -0.50383127,\n",
      "       -0.50696433, -0.52523643, -0.36835372, -0.17770123, -0.57045943,\n",
      "       -0.51936281, -0.67449647, -0.83812106, -0.57737392, -0.78203928,\n",
      "       -0.21196564, -0.37925491, -0.62798071, -0.7885434 , -0.18586478,\n",
      "       -0.36097595, -0.53572893, -0.62003452], dtype=float32), array([[[ -1.15669584e-02,   6.93232473e-03,  -4.40738983e-02, ...,\n",
      "          -3.02987313e-03,   4.63283854e-03,  -5.49349450e-02],\n",
      "        [ -7.90873021e-02,   1.80368777e-02,   8.08131881e-03, ...,\n",
      "           1.47690967e-01,   3.48680094e-02,  -1.85027067e-02],\n",
      "        [ -2.02950817e-02,   2.48247162e-02,  -1.16552012e-02, ...,\n",
      "           4.02795598e-02,  -7.72905722e-02,  -8.19765776e-03],\n",
      "        ..., \n",
      "        [ -8.83082598e-02,   3.47010717e-02,   1.54146627e-01, ...,\n",
      "           5.86850420e-02,  -1.12001508e-01,  -1.89207047e-02],\n",
      "        [  3.87844071e-02,   2.08526105e-02,  -7.41119757e-02, ...,\n",
      "           9.55903232e-02,   1.58206210e-01,   3.77816893e-02],\n",
      "        [ -1.06279626e-01,   1.99163258e-02,  -8.83457810e-02, ...,\n",
      "           1.73295572e-01,   7.57088885e-02,  -5.43058030e-02]],\n",
      "\n",
      "       [[  5.39394990e-02,  -4.01211791e-02,  -1.11790344e-01, ...,\n",
      "           1.34910718e-01,  -7.70762786e-02,  -7.05171973e-02],\n",
      "        [ -5.96877858e-02,   8.42996500e-03,   3.73045616e-02, ...,\n",
      "           1.25161618e-01,  -4.70734537e-02,  -2.57795993e-02],\n",
      "        [ -8.44073221e-02,   1.74755789e-02,   4.51801717e-02, ...,\n",
      "           1.41850719e-03,  -8.60615447e-02,  -7.78727531e-02],\n",
      "        ..., \n",
      "        [  8.14977661e-02,  -2.46408191e-02,   1.95947103e-02, ...,\n",
      "           1.60608903e-01,   1.57363251e-01,  -2.27259938e-02],\n",
      "        [ -3.09231356e-02,  -3.80843282e-02,   1.06171399e-01, ...,\n",
      "           1.69410333e-01,   1.58479735e-01,   1.71376728e-02],\n",
      "        [  3.59521434e-02,  -3.19376476e-02,   1.25640733e-02, ...,\n",
      "           5.82037084e-02,   1.66564155e-02,  -3.79954604e-03]],\n",
      "\n",
      "       [[  2.80879736e-02,   6.48163073e-03,   2.93601509e-02, ...,\n",
      "           3.02010551e-02,  -1.67619392e-01,   2.04915274e-02],\n",
      "        [ -2.26129196e-03,   1.91784035e-02,   1.85447820e-02, ...,\n",
      "           8.79057944e-02,   1.04443636e-02,  -6.41295537e-02],\n",
      "        [  4.44888957e-02,  -2.82950234e-02,   7.52877444e-02, ...,\n",
      "          -4.49888175e-05,  -6.38645217e-02,   4.02982906e-02],\n",
      "        ..., \n",
      "        [ -4.29722527e-03,  -3.64931524e-02,   2.23045930e-01, ...,\n",
      "           1.19943544e-01,   3.99422161e-02,  -3.19918096e-02],\n",
      "        [ -6.15720749e-02,  -3.38677764e-02,   1.54666767e-01, ...,\n",
      "           8.53348225e-02,   1.01756431e-01,   6.72169104e-02],\n",
      "        [  5.76837396e-04,  -4.02873941e-02,   8.63563865e-02, ...,\n",
      "           2.79140938e-02,   6.37192056e-02,  -2.11872011e-02]],\n",
      "\n",
      "       ..., \n",
      "       [[ -7.55094886e-02,  -4.98584919e-02,  -9.77921765e-03, ...,\n",
      "          -9.09354016e-02,  -8.12114403e-02,   8.62397477e-02],\n",
      "        [ -8.34153369e-02,   1.70436800e-02,   1.19862005e-01, ...,\n",
      "          -1.61841884e-01,  -5.59494123e-02,  -5.53638227e-02],\n",
      "        [ -6.13878071e-02,   2.06860360e-02,  -8.67685396e-03, ...,\n",
      "           8.14985409e-02,   2.30011418e-02,   2.31521912e-02],\n",
      "        ..., \n",
      "        [ -1.04672842e-01,  -2.88373604e-03,   1.62998289e-01, ...,\n",
      "          -1.11915201e-01,   9.97228250e-02,  -1.61661848e-01],\n",
      "        [ -5.25918640e-02,  -1.16622131e-02,   1.49537086e-01, ...,\n",
      "          -1.39440432e-01,   3.73749547e-02,   1.03132211e-01],\n",
      "        [ -6.89608231e-02,   2.05955952e-02,   1.26480341e-01, ...,\n",
      "          -1.33913159e-02,  -5.43175153e-02,   2.56654266e-02]],\n",
      "\n",
      "       [[ -8.44207592e-03,  -4.43761945e-02,  -2.68111564e-02, ...,\n",
      "          -1.59234047e-01,  -5.77759780e-02,  -3.75367291e-02],\n",
      "        [  3.25250737e-02,  -1.36004863e-02,   2.33099535e-02, ...,\n",
      "          -1.47716939e-01,  -8.26922655e-02,  -6.37815893e-02],\n",
      "        [ -4.45167236e-02,  -2.12839283e-02,  -1.18038677e-01, ...,\n",
      "          -2.75694523e-02,  -8.99585430e-03,  -9.60992649e-02],\n",
      "        ..., \n",
      "        [ -7.56155029e-02,  -2.40055639e-02,  -1.58674479e-01, ...,\n",
      "          -2.04192325e-01,   2.18799654e-02,  -1.60635754e-01],\n",
      "        [ -1.03955746e-01,   1.33668585e-02,   1.72874287e-01, ...,\n",
      "          -8.07486475e-02,  -3.64119485e-02,   5.34535386e-02],\n",
      "        [  5.12568606e-03,  -1.14749437e-02,   3.87746356e-02, ...,\n",
      "          -2.26670019e-02,  -6.85344711e-02,  -1.29240289e-01]],\n",
      "\n",
      "       [[ -8.31795111e-02,  -3.59044597e-02,   1.92963675e-01, ...,\n",
      "          -7.18043149e-02,  -7.32272863e-02,   4.89028767e-02],\n",
      "        [ -3.30135226e-02,   1.69227365e-03,   1.82258680e-01, ...,\n",
      "          -2.29063436e-01,  -6.56765178e-02,   5.87375788e-03],\n",
      "        [  3.20512280e-02,   2.70568095e-02,  -3.55379544e-02, ...,\n",
      "           2.80618407e-02,  -5.15696742e-02,   1.63631123e-02],\n",
      "        ..., \n",
      "        [ -8.19762498e-02,   3.14774439e-02,   6.12248033e-02, ...,\n",
      "          -1.90501347e-01,  -4.95162010e-02,  -1.85961992e-01],\n",
      "        [ -5.18815890e-02,  -1.63928252e-02,   1.50244400e-01, ...,\n",
      "          -1.51158586e-01,  -4.00310867e-02,  -4.93458509e-02],\n",
      "        [ -7.54491379e-03,  -8.11897125e-03,   1.24619201e-01, ...,\n",
      "          -2.08756188e-03,   7.48306289e-02,   3.94667275e-02]]], dtype=float32), array([ 0.01209155, -0.02541326, -0.03280094, -0.02552093,  0.09225345,\n",
      "        0.10399728, -0.02800798, -0.07941631, -0.01988352, -0.03010307,\n",
      "       -0.00665425, -0.01605153, -0.01735235,  0.00622328, -0.01734387,\n",
      "        0.10430016, -0.00670092,  0.1016203 , -0.12285451, -0.00631937,\n",
      "       -0.25522923, -0.07204644, -0.01514096, -0.05219879,  0.01980297,\n",
      "       -0.15363891, -0.12706473, -0.01291005, -0.01642231, -0.05715901,\n",
      "       -0.03334465, -0.13353702, -0.00421116, -0.01468706, -0.01407742,\n",
      "       -0.03915516, -0.10387876, -0.12956598, -0.20713063, -0.07899194,\n",
      "       -0.10134403,  0.20130256,  0.06646717, -0.14981315, -0.00646334,\n",
      "       -0.02859524,  0.07185369,  0.05900233, -0.05497036, -0.02635858,\n",
      "        0.20635112, -0.40262675, -0.25343767, -0.03365505, -0.02110756,\n",
      "       -0.17480934, -0.07504711,  0.09871823, -0.05643219, -0.035095  ,\n",
      "       -0.06143814, -0.00590045, -0.05349505, -0.02081373, -0.17520151,\n",
      "       -0.02397247, -0.01921048, -0.29417378,  0.18154946, -0.05761383,\n",
      "       -0.00725241,  0.20132296, -0.03967818, -0.10723116,  0.03736273,\n",
      "       -0.03370275, -0.02502158, -0.07199381, -0.0069063 ,  0.25718546,\n",
      "        0.04535254,  0.04822157, -0.12239172,  0.08876156, -0.12716709,\n",
      "        0.04339434,  0.27627859, -0.2956925 , -0.03284155, -0.00985132,\n",
      "        0.00229546, -0.0429955 , -0.00708464, -0.02189988, -0.17294076,\n",
      "       -0.01456379, -0.03771034, -0.08765782, -0.00338868, -0.01475461,\n",
      "       -0.00580723, -0.01866665, -0.04079012, -0.02143833, -0.41686967,\n",
      "       -0.01075172, -0.11282553, -0.28579822, -0.02008038, -0.01569255,\n",
      "        0.04194756,  0.02700086, -0.0192056 ,  0.05857767, -0.01850062,\n",
      "       -0.09770833, -0.01922259, -0.02063501, -0.05398138, -0.17224881,\n",
      "        0.08122509, -0.02448651, -0.29354656, -0.01046724, -0.01111753,\n",
      "       -0.16718794,  0.00666471, -0.18177828], dtype=float32), array([[-0.02860787,  0.00135164, -0.17828174, ...,  0.07398607,\n",
      "         0.00222725, -0.01984667],\n",
      "       [-0.00077665,  0.06164572,  0.02225055, ...,  0.04493265,\n",
      "         0.05096891,  0.01939372],\n",
      "       [-0.14282152,  0.00664602, -0.16691458, ..., -0.01158492,\n",
      "         0.03627714, -0.08519767],\n",
      "       ..., \n",
      "       [-0.01748001, -0.00722961, -0.04895964, ..., -0.12615852,\n",
      "        -0.07527402, -0.01435335],\n",
      "       [ 0.12817456,  0.06806645,  0.2822006 , ...,  0.06397865,\n",
      "        -0.10945978, -0.12921649],\n",
      "       [-0.1024779 , -0.06731103, -0.00607624, ..., -0.01170591,\n",
      "         0.12151701,  0.16547942]], dtype=float32), array([[-0.02438368, -0.15195568, -0.06793755, ..., -0.08296386,\n",
      "         0.06432117, -0.05725584],\n",
      "       [ 0.06129021,  0.13367406,  0.07592271, ...,  0.10533673,\n",
      "        -0.07721106, -0.01990618],\n",
      "       [-0.16958576, -0.1631677 , -0.14258793, ..., -0.07296433,\n",
      "        -0.22658734, -0.22262342],\n",
      "       ..., \n",
      "       [-0.12960449,  0.04150247,  0.22603238, ...,  0.12303896,\n",
      "         0.1113373 ,  0.20148741],\n",
      "       [ 0.08464627,  0.01064991, -0.11119217, ...,  0.00767337,\n",
      "        -0.16813117, -0.00376523],\n",
      "       [ 0.069353  , -0.19192307, -0.07227942, ..., -0.21735552,\n",
      "         0.11022688, -0.08353562]], dtype=float32), array([ -2.83524245e-02,  -2.38886774e-01,  -4.08750884e-02,\n",
      "         6.52339682e-02,  -5.88874705e-02,   2.50451211e-02,\n",
      "         1.14060014e-01,  -2.01180145e-01,  -9.38379243e-02,\n",
      "        -9.74185094e-02,  -8.77980813e-02,  -4.76767309e-03,\n",
      "        -5.01918234e-02,   9.09605250e-02,   8.05989802e-02,\n",
      "         1.17395736e-01,  -2.21039932e-02,   1.64136231e-01,\n",
      "         7.19160726e-03,   9.91238430e-02,   3.62165533e-02,\n",
      "         4.08939868e-02,   5.26939817e-02,   6.71344995e-02,\n",
      "         5.88490032e-02,   3.86819988e-02,  -1.28332108e-01,\n",
      "         5.42225782e-03,   1.18598312e-01,  -1.14128336e-01,\n",
      "         1.60290450e-02,   5.94596490e-02,  -1.33796826e-01,\n",
      "        -1.54472888e-02,  -1.57649699e-03,   8.16303343e-02,\n",
      "        -3.53959352e-02,  -4.54047322e-02,  -3.39600369e-02,\n",
      "        -4.31032851e-02,   9.85208005e-02,  -4.06594984e-02,\n",
      "        -7.64897019e-02,   1.15751386e-01,  -1.66405812e-02,\n",
      "         6.27466738e-02,  -1.56588554e-01,  -1.32717174e-02,\n",
      "        -1.11977786e-01,  -1.20316125e-01,   1.13782220e-01,\n",
      "        -9.78131071e-02,  -1.42945990e-01,   4.60338593e-02,\n",
      "         1.32687122e-01,  -2.90339533e-02,   1.31574720e-01,\n",
      "         3.20651233e-02,   9.66509432e-02,  -5.12172608e-03,\n",
      "        -6.14968315e-02,  -9.21836682e-03,   1.49327591e-01,\n",
      "        -4.88196947e-02,  -7.53266132e-03,   7.81936124e-02,\n",
      "        -1.01165418e-02,  -1.21492594e-01,   6.82959110e-02,\n",
      "        -7.10725114e-02,   9.25268382e-02,  -1.86946872e-03,\n",
      "         6.61616772e-02,   3.89356203e-02,   8.88660699e-02,\n",
      "        -2.77217906e-02,   8.23300704e-02,  -5.03190272e-02,\n",
      "         1.18959974e-02,  -9.87102538e-02,   5.66593260e-02,\n",
      "         9.59032699e-02,  -1.67125344e-01,  -1.07821502e-01,\n",
      "         4.68766205e-02,  -8.76943320e-02,   1.26987666e-01,\n",
      "        -1.33591577e-01,  -1.96820144e-02,  -2.29848158e-02,\n",
      "        -1.28265291e-01,   1.06398337e-01,   2.48078257e-02,\n",
      "         2.63592061e-02,   9.64657441e-02,   4.90288064e-03,\n",
      "        -1.28448427e-01,   1.90362379e-01,   2.20167749e-02,\n",
      "         1.27964348e-01,  -5.73316924e-02,   3.15957540e-03,\n",
      "         7.94432312e-02,  -1.20450668e-01,   1.86315164e-01,\n",
      "         2.37965938e-02,   1.19333155e-01,  -1.40786856e-01,\n",
      "         2.42423117e-02,   2.30089817e-02,  -1.51288826e-02,\n",
      "        -9.39554945e-02,   4.57821973e-02,   1.16246939e-01,\n",
      "         3.34826938e-04,   7.83341601e-02,  -1.07185659e-03,\n",
      "         7.72333369e-02,  -4.45403904e-02,  -1.36522260e-02,\n",
      "         1.04455814e-01,   1.89393997e-01,  -1.58078093e-02,\n",
      "         1.06583238e-01,   8.81829262e-02,  -6.15132637e-02,\n",
      "         2.72829854e-03,   4.42611687e-02,   1.06071937e+00,\n",
      "         8.44805121e-01,   1.08447194e+00,   1.05238402e+00,\n",
      "         1.03209472e+00,   1.12872994e+00,   9.99930203e-01,\n",
      "         1.04828072e+00,   8.85531962e-01,   9.54726756e-01,\n",
      "         1.06935501e+00,   1.03301394e+00,   1.08332253e+00,\n",
      "         9.94934857e-01,   9.88169909e-01,   1.12944543e+00,\n",
      "         1.10204327e+00,   1.06762016e+00,   1.06312835e+00,\n",
      "         9.47505414e-01,   1.05724776e+00,   9.31061029e-01,\n",
      "         8.72750163e-01,   1.11027026e+00,   9.30085719e-01,\n",
      "         1.11113608e+00,   1.09634268e+00,   1.02825856e+00,\n",
      "         1.02363586e+00,   1.19460416e+00,   9.49205518e-01,\n",
      "         1.07900274e+00,   8.94735813e-01,   1.04493654e+00,\n",
      "         1.06254768e+00,   1.09835458e+00,   9.49345052e-01,\n",
      "         1.02958405e+00,   1.01752675e+00,   1.07149255e+00,\n",
      "         9.84851360e-01,   9.81893241e-01,   1.12396777e+00,\n",
      "         1.04396927e+00,   9.80283737e-01,   1.00587392e+00,\n",
      "         9.49497819e-01,   1.01025057e+00,   1.04645777e+00,\n",
      "         9.64995444e-01,   1.13132548e+00,   1.08753908e+00,\n",
      "         8.94741297e-01,   1.15233731e+00,   1.09711504e+00,\n",
      "         9.80931759e-01,   1.08467877e+00,   1.09570193e+00,\n",
      "         1.02379847e+00,   1.00017786e+00,   1.02467918e+00,\n",
      "         9.44879591e-01,   9.07898545e-01,   9.97142494e-01,\n",
      "         1.09695029e+00,   1.11094677e+00,   1.04006851e+00,\n",
      "         9.62722659e-01,   1.05651391e+00,   1.07312608e+00,\n",
      "         1.09238482e+00,   1.15850472e+00,   1.09954715e+00,\n",
      "         1.01989102e+00,   1.08907950e+00,   1.08574462e+00,\n",
      "         1.06253135e+00,   9.42596912e-01,   9.79906380e-01,\n",
      "         1.08671069e+00,   1.05071878e+00,   9.38220739e-01,\n",
      "         1.04332960e+00,   1.01373994e+00,   1.07140720e+00,\n",
      "         1.05182457e+00,   1.04448712e+00,   1.02182484e+00,\n",
      "         1.11119354e+00,   9.98966157e-01,   9.85652924e-01,\n",
      "         1.08004808e+00,   1.02529168e+00,   9.86696422e-01,\n",
      "         1.04547668e+00,   1.09197450e+00,   1.04917932e+00,\n",
      "         1.00369322e+00,   1.05885184e+00,   1.06104779e+00,\n",
      "         9.38759387e-01,   1.02623820e+00,   1.06216407e+00,\n",
      "         9.48502362e-01,   1.09288669e+00,   9.25213993e-01,\n",
      "         1.08213699e+00,   1.06647646e+00,   1.12681198e+00,\n",
      "         1.07687294e+00,   1.03814185e+00,   9.94074881e-01,\n",
      "         1.01455212e+00,   1.03456891e+00,   1.06886733e+00,\n",
      "         1.08834410e+00,   1.03386128e+00,   9.88097608e-01,\n",
      "         9.65949953e-01,   1.03849125e+00,   1.02813578e+00,\n",
      "         1.06498718e+00,   1.00260580e+00,   1.12273741e+00,\n",
      "         9.38179791e-01,   8.81711602e-01,   1.01177454e+00,\n",
      "         1.06932390e+00,   5.54429255e-02,  -9.34729725e-02,\n",
      "         1.15545072e-01,   9.35742930e-02,  -1.26133412e-01,\n",
      "        -2.45067123e-02,  -7.77179608e-03,   7.69449174e-02,\n",
      "        -1.06784135e-01,   7.47845024e-02,   5.54687604e-02,\n",
      "        -2.01642942e-02,   7.14140385e-02,  -2.83977240e-02,\n",
      "         1.58379786e-02,   1.68617785e-01,  -1.74704229e-03,\n",
      "        -9.24815908e-02,   8.99288524e-03,  -6.77282885e-02,\n",
      "        -4.25021723e-02,  -2.81058345e-02,   9.62941200e-02,\n",
      "         4.93112691e-02,   5.62672503e-02,  -1.09333970e-01,\n",
      "         1.86211705e-01,   6.00032397e-02,  -6.69742972e-02,\n",
      "        -4.44423705e-02,   6.49134349e-03,   1.03535391e-01,\n",
      "        -1.28201321e-01,   7.81050399e-02,   2.86948476e-02,\n",
      "         3.94127779e-02,  -1.56610712e-01,  -8.43332410e-02,\n",
      "         1.83506578e-01,   8.24557841e-02,  -5.36025055e-02,\n",
      "        -5.28586842e-02,  -1.69877037e-01,  -7.32014254e-02,\n",
      "         8.41911584e-02,   1.57220200e-01,   2.48836949e-02,\n",
      "        -4.44961488e-02,  -1.55102629e-02,   1.36406645e-01,\n",
      "         1.57861218e-01,  -3.61425616e-02,  -2.92730834e-02,\n",
      "        -6.53420910e-02,   1.11895412e-01,  -7.46195391e-02,\n",
      "         1.11328818e-01,  -2.84656137e-03,   8.09239782e-03,\n",
      "         3.62509005e-02,   7.36763775e-02,   7.90907070e-02,\n",
      "        -6.85235951e-03,   7.57001564e-02,   9.00601968e-02,\n",
      "        -1.68440398e-02,  -2.78962106e-02,   1.03214845e-01,\n",
      "         1.67094499e-01,  -3.78882326e-02,  -1.96040615e-01,\n",
      "         8.54016170e-02,  -3.12132505e-03,  -8.19611270e-03,\n",
      "        -1.78433005e-02,  -5.60433492e-02,   6.68297336e-02,\n",
      "        -7.63366222e-02,   4.55148630e-02,   1.73150394e-02,\n",
      "         2.90462039e-02,   9.31919515e-02,  -4.00053225e-02,\n",
      "        -9.56722796e-02,   5.38822338e-02,  -6.52211234e-02,\n",
      "        -3.95206772e-02,  -4.43454608e-02,  -8.12446699e-02,\n",
      "        -6.37116507e-02,  -4.11037244e-02,  -4.87391017e-02,\n",
      "         1.09090313e-01,   2.61322428e-02,   1.10168293e-01,\n",
      "         4.42057401e-02,   1.29113704e-01,   5.97957186e-02,\n",
      "         8.78148004e-02,  -4.99893837e-02,   5.76347224e-02,\n",
      "        -2.20986903e-02,   9.63291004e-02,  -4.85547222e-02,\n",
      "         4.70952764e-02,   1.08112190e-02,   4.61372687e-03,\n",
      "         1.23130716e-02,   1.88459605e-02,   2.62952205e-02,\n",
      "        -1.16046488e-01,  -3.57865356e-03,   1.14995904e-01,\n",
      "         2.78716832e-02,  -5.36481701e-02,  -1.50571972e-01,\n",
      "         6.47322759e-02,   1.33258343e-01,  -7.56080635e-03,\n",
      "        -5.06834239e-02,   1.14607848e-01,  -3.53477709e-02,\n",
      "         1.56797972e-02,   7.18979314e-02,  -7.52688944e-02,\n",
      "        -1.41855180e-01,   9.21904051e-04,   4.70059067e-02,\n",
      "        -1.00086898e-01,  -1.48269176e-01,   5.72011657e-02,\n",
      "         6.02331199e-03,   6.06393814e-02,  -1.70775019e-02,\n",
      "        -1.15505353e-01,  -2.41979450e-01,   2.97286883e-02,\n",
      "        -6.97080866e-02,   8.32451042e-04,  -3.55754830e-02,\n",
      "         6.74964711e-02,   3.15915048e-02,  -7.76949674e-02,\n",
      "         5.88876605e-02,   8.89349729e-03,   1.21193584e-02,\n",
      "        -1.15634993e-01,   9.22721997e-02,  -6.02818206e-02,\n",
      "        -2.69002561e-02,   6.17636554e-02,   4.63117473e-02,\n",
      "         1.37811592e-02,   2.55881809e-02,  -5.85591719e-02,\n",
      "        -7.39538670e-02,   1.46700054e-01,  -3.43371406e-02,\n",
      "         3.06928102e-02,   4.16501984e-02,   1.21052943e-01,\n",
      "        -1.47948535e-02,   5.14849871e-02,  -1.46663636e-01,\n",
      "         1.07781939e-01,   2.28693038e-01,  -1.21055424e-01,\n",
      "        -1.27683565e-01,   3.81824300e-02,   1.10448517e-01,\n",
      "        -2.44377822e-01,  -5.04733250e-02,  -1.36051089e-01,\n",
      "         1.07682116e-01,   4.04961258e-02,  -1.11317143e-01,\n",
      "        -2.06544846e-01,  -1.83713943e-01,   9.27407201e-03,\n",
      "         7.28053153e-02,  -7.99273923e-02,   8.90174434e-02,\n",
      "         9.67693701e-02,   7.77434409e-02,  -4.25355174e-02,\n",
      "        -6.93870261e-02,   1.14747979e-01,  -8.66828337e-02,\n",
      "        -1.38738185e-01,   6.77642832e-03,   1.21308178e-01,\n",
      "         1.21167809e-01,  -2.68090487e-01,   5.57477437e-02,\n",
      "         4.27933149e-02,   1.07548162e-01,  -1.56450048e-01,\n",
      "        -6.86494932e-02,   2.46747658e-02,  -1.23797677e-01,\n",
      "         1.13061421e-01,   1.40233845e-01,   6.59303963e-02,\n",
      "         8.98853838e-02,  -1.21849947e-01,   2.69692000e-02,\n",
      "        -4.76479083e-02,  -1.02763072e-01,   1.02650672e-02,\n",
      "        -5.45699000e-02,  -6.13698699e-02,  -1.25042096e-01,\n",
      "         1.04158051e-01,  -3.83113809e-02,   5.75923063e-02,\n",
      "        -4.84357327e-02,   1.18565291e-01,   1.70511141e-01,\n",
      "        -1.90639794e-01,  -9.89776179e-02,   1.77448168e-02,\n",
      "         2.97945039e-03,   6.52476447e-03,   5.30439056e-02,\n",
      "        -6.85770959e-02,   6.11855127e-02,  -5.75352833e-02,\n",
      "         9.54541862e-02,  -6.69495687e-02,  -1.30758539e-01,\n",
      "        -1.75236538e-02,   9.75633934e-02,   1.13234267e-01,\n",
      "        -9.64905098e-02,   1.67902038e-01,   5.53140379e-02,\n",
      "        -2.03114096e-02,  -7.80587718e-02,   1.08536109e-01,\n",
      "        -1.03881240e-01,  -2.42632955e-01,   1.12036407e-01,\n",
      "         5.43745458e-02,   8.86771530e-02,   6.39824495e-02,\n",
      "        -4.10360508e-02,  -6.49483129e-02,  -6.08273558e-02,\n",
      "         5.42618968e-02,  -5.67773767e-02,  -2.50270367e-01,\n",
      "         6.10290375e-03,   4.70751710e-02,  -9.54150483e-02,\n",
      "        -1.64537385e-01,  -7.86607936e-02], dtype=float32), array([[-0.03253394, -0.03241171, -0.04366527, ..., -0.10137495,\n",
      "        -0.00684739, -0.13587365],\n",
      "       [ 0.18096286,  0.23367536, -0.17336027, ...,  0.11082644,\n",
      "        -0.03461728, -0.19394876],\n",
      "       [-0.2258829 ,  0.0565038 , -0.04604362, ..., -0.09092402,\n",
      "         0.05173948,  0.14419523],\n",
      "       ..., \n",
      "       [-0.18515581,  0.29707932, -0.09954105, ..., -0.10296201,\n",
      "        -0.18628618,  0.09126595],\n",
      "       [-0.090887  , -0.0059738 ,  0.21995965, ...,  0.08888972,\n",
      "         0.20673291,  0.11759223],\n",
      "       [ 0.17313355,  0.23543791, -0.33034447, ...,  0.08836797,\n",
      "        -0.09759194,  0.27638444]], dtype=float32), array([-0.03363599, -0.0207724 , -0.0341601 , -0.01537189,  0.04705537,\n",
      "       -0.05216746, -0.02245252, -0.04360926,  0.02247106, -0.04100625,\n",
      "       -0.02444285, -0.00175905,  0.00210645, -0.0120788 ,  0.00230752,\n",
      "        0.08450753, -0.01434204,  0.08004424, -0.08643126, -0.00367099,\n",
      "       -0.02093172,  0.06046086, -0.10316975,  0.0114719 ,  0.03480645,\n",
      "       -0.09978054,  0.01824138, -0.03415392,  0.03329638,  0.06132153,\n",
      "        0.04752916, -0.03370735,  0.00894681,  0.06235628, -0.05213278,\n",
      "        0.01424657, -0.00029116,  0.01673651,  0.02284566, -0.03797133,\n",
      "        0.06966516,  0.0683435 , -0.04249508, -0.01174293, -0.02203969,\n",
      "        0.03103657,  0.00811872, -0.04618619, -0.01135383,  0.03156878,\n",
      "       -0.00692046, -0.04075165, -0.01600139, -0.01270105, -0.00576236,\n",
      "       -0.00190529,  0.00717668,  0.02278782, -0.02070141, -0.00643874,\n",
      "       -0.00941925, -0.03178004,  0.0398546 ,  0.02137645,  0.00161047,\n",
      "        0.01358396, -0.00172166, -0.00433331,  0.00698749, -0.00062449,\n",
      "       -0.02569873, -0.00275718, -0.00385929, -0.03890842,  0.04914595,\n",
      "       -0.04219969,  0.04663147,  0.01935174, -0.00398323, -0.05425457,\n",
      "        0.01271347,  0.02771175,  0.00354812, -0.00662315,  0.00723481,\n",
      "        0.06039026,  0.02181707, -0.00629845,  0.00594022, -0.02505221,\n",
      "        0.05451057,  0.01848275, -0.01997499, -0.0044342 ,  0.02676237,\n",
      "        0.01544533, -0.03497868, -0.03166529,  0.0290045 , -0.02855963,\n",
      "       -0.07975125, -0.01059922, -0.04894674,  0.03017769,  0.01557573,\n",
      "        0.05370934, -0.04053466, -0.00123275,  0.04106052,  0.01208511,\n",
      "       -0.02098886,  0.04978338,  0.01749134,  0.00083435,  0.07550818,\n",
      "        0.01959242, -0.02208496,  0.0231089 ,  0.00320789,  0.0386607 ,\n",
      "        0.01543243, -0.02985486,  0.05523587, -0.01225159,  0.02634321,\n",
      "       -0.05206482, -0.0539835 , -0.0261088 , -0.0193185 ,  0.0278364 ,\n",
      "        0.05241744,  0.06261717,  0.01484198, -0.07274083, -0.07082771,\n",
      "       -0.00143535, -0.02423239, -0.05795199,  0.06717747, -0.02859194,\n",
      "        0.00978   ,  0.03326469, -0.06635861, -0.0241126 ,  0.0577678 ,\n",
      "        0.00401571, -0.02952305, -0.03752189,  0.01328538, -0.04223499,\n",
      "        0.02757377, -0.06292474,  0.01774829,  0.07549619,  0.00616532,\n",
      "       -0.04480321, -0.00079364,  0.00858794, -0.01054579,  0.0493301 ,\n",
      "        0.00486436,  0.00536922, -0.02683462, -0.07444836,  0.00778395,\n",
      "       -0.01401471, -0.01885001,  0.02533897,  0.05809985,  0.02075107,\n",
      "       -0.00222257, -0.05461005,  0.03297495, -0.05402227,  0.03342325,\n",
      "        0.02533696,  0.03251236,  0.06416937,  0.02416636, -0.05420378,\n",
      "       -0.00971063,  0.02764606,  0.01341102, -0.01171486, -0.04706324,\n",
      "        0.03721015, -0.01475211,  0.04664179,  0.03657809, -0.0033943 ,\n",
      "        0.01400871, -0.00237714,  0.08990128, -0.05310919, -0.00391022,\n",
      "       -0.04674983,  0.03632126,  0.02424493, -0.01302318, -0.00510557,\n",
      "        0.0378959 , -0.01170057,  0.02872874, -0.01318427,  0.03109149,\n",
      "        0.02670019, -0.05542338,  0.06388307,  0.06335452, -0.04168781,\n",
      "        0.00961982, -0.02794698, -0.06352644,  0.05730806,  0.0503642 ,\n",
      "        0.07686696,  0.02467221,  0.04283469, -0.04992871, -0.05872917,\n",
      "       -0.00034859, -0.006608  ,  0.08074427,  0.02528632, -0.07235519,\n",
      "       -0.05702104, -0.03511247, -0.01937064, -0.01550519, -0.06384377,\n",
      "        0.03234705, -0.05561015,  0.01548811, -0.01297263,  0.06041676,\n",
      "        0.02548365, -0.07600918, -0.02539739, -0.07557982,  0.04527856,\n",
      "        0.03123852,  0.07004115, -0.03647069,  0.0288907 , -0.01537012,\n",
      "       -0.04351358,  0.07198705, -0.04256801, -0.00064269, -0.03518666,\n",
      "        0.00490642, -0.03183994, -0.02406995,  0.00910181,  0.01420837,\n",
      "        0.02308537], dtype=float32), array([[-0.11947545, -0.08925731,  0.07824816,  0.10619374, -0.09161083,\n",
      "         0.01534796],\n",
      "       [-0.11517028, -0.07309223,  0.0209754 ,  0.0357415 ,  0.01288306,\n",
      "         0.06404727],\n",
      "       [ 0.04417262,  0.17489384,  0.2208923 ,  0.25139302, -0.01007136,\n",
      "         0.02498722],\n",
      "       ..., \n",
      "       [ 0.0017597 ,  0.09053029,  0.02770135, -0.13166797, -0.00957581,\n",
      "         0.09876176],\n",
      "       [-0.12887277,  0.03918628, -0.0072658 , -0.04058078, -0.15112841,\n",
      "        -0.01367267],\n",
      "       [ 0.17472658,  0.07907934, -0.28313795, -0.10589264,  0.11546073,\n",
      "         0.17145576]], dtype=float32), array([ 0.05957757, -0.03929437, -0.09246194, -0.18780702,  0.0236203 ,\n",
      "        0.02586295], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(m.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1001's data\n",
      "Loading 1002's data\n",
      "Loading 1003's data\n",
      "Loading 1004's data\n",
      "Loading 1005's data\n",
      "Loading 1006's data\n",
      "Loading 1007's data\n",
      "Loading 1008's data\n",
      "Loading 1009's data\n",
      "Loading 1010's data\n",
      "Loading 1011's data\n",
      "Loading 1012's data\n",
      "Loading 2001's data\n",
      "Loading 2002's data\n",
      "Finished loading\n"
     ]
    }
   ],
   "source": [
    "%run load_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run preprocess_for_SVM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subj_train = ['1001','1002','1003','2001']\n",
    "subj_val = ['1004','1005','1006','2002']\n",
    "subj_test = ['1007','1008','1009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_y(subj_ids, X, y, s):\n",
    "    X_get = []\n",
    "    y_get = []\n",
    "    s_get = []\n",
    "    for i in range(len(s)):\n",
    "        for j in range(len(subj_ids)):\n",
    "            if(s[i]==subj_ids[j]):\n",
    "                X_get.append(X[i])\n",
    "                y_get.append(y[i])\n",
    "                s_get.append(s[i])\n",
    "                \n",
    "    return np.array(X_get), np.array(y_get), np.array(s_get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, s_train = get_X_y(subj_train, X_all, y_all, subj_all)\n",
    "X_val, y_val, s_val = get_X_y(subj_val, X_all, y_all, subj_all)\n",
    "X_test, y_test, s_test = get_X_y(subj_test, X_all, y_all, subj_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_pure(X, y, subj_all, new_label_list):\n",
    "    X_label, y_label = label_grouping(X, y, subj_all, new_label_list)\n",
    "    \n",
    "    X_concat = []\n",
    "    y_concat = []\n",
    "    for i in range(len(X_label)):\n",
    "        for j in range(len(X_label[i])):\n",
    "            X_ol, y_ol = make_overlapping(np.array(X_label[i][j]), y_label[i][j])\n",
    "#             print(i, j, X_ol.shape)\n",
    "            \n",
    "            if(len(X_concat)==0):\n",
    "                X_concat = X_ol\n",
    "            else:\n",
    "                X_concat = np.vstack((X_concat, X_ol))\n",
    "\n",
    "            if(len(y_concat)==0):\n",
    "                y_concat = y_ol\n",
    "            else:\n",
    "                y_concat = np.hstack((y_concat, y_ol))\n",
    "                \n",
    "#     X_concat_xyz = concat_xyz(X_concat)\n",
    "    \n",
    "    return X_concat, y_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_label, y_label = label_grouping(X_train, y_train, s_train, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_list = [0,1,3,2,4]\n",
    "label_dict = {\n",
    "    0: 'sit',\n",
    "    1: 'sleep',\n",
    "    3: 'stand',\n",
    "    2: 'stairs',\n",
    "    4: 'walk'\n",
    "}\n",
    "\n",
    "all_subjects = subj_train\n",
    "X_train_pure, y_train_pure = prepare_pure(X_train, y_train, s_train, label_list)\n",
    "\n",
    "all_subjects = subj_val\n",
    "X_val_pure, y_val_pure = prepare_pure(X_val, y_val, s_val, label_list)\n",
    "\n",
    "all_subjects = subj_test\n",
    "X_test_pure, y_test_pure = prepare_pure(X_test, y_test, s_test, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6534\n"
     ]
    }
   ],
   "source": [
    "VAL_LEN = X_val_pure.shape[0]\n",
    "X_train_pure = X_train_pure[:VAL_LEN]\n",
    "y_train_pure = y_train_pure[:VAL_LEN]\n",
    "\n",
    "print(VAL_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL_COUNT = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_y(y, window_length=60):\n",
    "    \n",
    "    y_rs_ = label_binarize(y, classes=[0,1,2,3,4])\n",
    "    \n",
    "    y_rs = []\n",
    "    for i in range(len(y_rs_)):\n",
    "        y_temp = []\n",
    "        for j in range(window_length):\n",
    "            y_temp.append(y_rs_[i])\n",
    "            \n",
    "        y_rs.append(np.array(y_temp))\n",
    "        \n",
    "    y_rs = np.array(y_rs)\n",
    "    y_rs = y_rs.reshape((y_rs.shape[0],y_rs.shape[1],LABEL_COUNT))\n",
    "        \n",
    "    return np.array(y_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_X(X):\n",
    "    X_rs = X.reshape((X.shape[0],1,X.shape[1]))\n",
    "    return X_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y_train = np_utils.to_categorical(y_train, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_rs = reshape_y(y_train_pure)\n",
    "y_val_rs = reshape_y(y_val_pure)\n",
    "y_test_rs = reshape_y(y_test_pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6534, 60, 3)\n",
      "60\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pure.shape)\n",
    "print(X_train_pure.shape[1])\n",
    "print(X_train_pure.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run RNN_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer gru_8: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-70-36a0801827be>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrnn_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_rnn_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrnn_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-68-08431a4f3ca6>\u001b[0m in \u001b[0;36mcreate_rnn_model\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     16\u001b[0m                  input_shape=(X.shape[1], X.shape[2]))\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgru_layer_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    490\u001b[0m                           output_shapes=[self.outputs[0]._keras_shape])\n\u001b[0;32m    491\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 492\u001b[1;33m             \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    493\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    571\u001b[0m                 \u001b[1;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m                 \u001b[1;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 573\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    574\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m                 \u001b[1;31m# Collect input shapes to build layer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m    470\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m': expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    471\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 472\u001b[1;33m                                      str(K.ndim(x)))\n\u001b[0m\u001b[0;32m    473\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 is incompatible with layer gru_8: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "rnn_model = create_rnn_model(X_train_pure)\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_15 (LSTM)               (None, 60, 50)            10800     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 60, 50)            0         \n",
      "_________________________________________________________________\n",
      "lstm_16 (LSTM)               (None, 100)               60400     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 645       \n",
      "=================================================================\n",
      "Total params: 130,597\n",
      "Trainable params: 130,597\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm = lstm_model(X_train_pure)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer #0 (named \"lstm_15\" in the current model) was found to correspond to layer conv1d_1 in the save file. However the new layer lstm_15 expects 3 weights, but the saved weights have 2 elements.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-92-b5b8de1a370c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlstm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./model/model_1.2.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch)\u001b[0m\n\u001b[0;32m    735\u001b[0m                                                           skip_mismatch=skip_mismatch)\n\u001b[0;32m    736\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 737\u001b[1;33m             \u001b[0mtopology\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights_from_hdf5_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    738\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'close'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    739\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\topology.py\u001b[0m in \u001b[0;36mload_weights_from_hdf5_group\u001b[1;34m(f, layers)\u001b[0m\n\u001b[0;32m   3162\u001b[0m                              \u001b[1;34m' weights, but the saved weights have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3163\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3164\u001b[1;33m                              ' elements.')\n\u001b[0m\u001b[0;32m   3165\u001b[0m         \u001b[0mweight_value_tuples\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msymbolic_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3166\u001b[0m     \u001b[0mK\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_set_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight_value_tuples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Layer #0 (named \"lstm_15\" in the current model) was found to correspond to layer conv1d_1 in the save file. However the new layer lstm_15 expects 3 weights, but the saved weights have 2 elements."
     ]
    }
   ],
   "source": [
    "lstm.load_weights(\"./model/model_1.2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compile_model(lstm_model)\n",
    "train_model(lstm_model, X_train_pure, y_train_rs, \n",
    "                        X_val_pure, y_val_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = get_y_predict(rnn_model, X_test_pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_y(y):\n",
    "    y_conv = [j for i in range(len(y)) for j in range(len(y[i][0])) if y[i][0][j]==np.amax(y[i][0])]\n",
    "    return np.array(y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_t = convert_y(y_test_rs)\n",
    "y_p = convert_y(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run eval_score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = list(label_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_conf_matrix(y_t, y_p, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_clf_report(y_t, y_p, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# score = history.evaluate(X_test,y_test,verbose=2)\n",
    "print('Baseline Error: %.2f%%' %(100-score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
