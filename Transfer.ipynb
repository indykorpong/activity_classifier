{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg19 import VGG19, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "from time import time\n",
    "from keras.models import load_model\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(12)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(12)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(12)\n",
    "from scipy import stats\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score\n",
    "import glob\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_dataset = \"Dataset/WISDM/WISDM_ar_v1.1/a.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>activity</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>x-axis</th>\n",
       "      <th>y-axis</th>\n",
       "      <th>z-axis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49105962326000</td>\n",
       "      <td>-0.694638</td>\n",
       "      <td>12.680544</td>\n",
       "      <td>0.503953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106062271000</td>\n",
       "      <td>5.012288</td>\n",
       "      <td>11.264028</td>\n",
       "      <td>0.953424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106112167000</td>\n",
       "      <td>4.903325</td>\n",
       "      <td>10.882658</td>\n",
       "      <td>-0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106222305000</td>\n",
       "      <td>-0.612916</td>\n",
       "      <td>18.496431</td>\n",
       "      <td>3.023717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106332290000</td>\n",
       "      <td>-1.184970</td>\n",
       "      <td>12.108489</td>\n",
       "      <td>7.205164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106442306000</td>\n",
       "      <td>1.375655</td>\n",
       "      <td>-2.492524</td>\n",
       "      <td>-6.510526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106542312000</td>\n",
       "      <td>-0.612916</td>\n",
       "      <td>10.569390</td>\n",
       "      <td>5.706926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106652389000</td>\n",
       "      <td>-0.503953</td>\n",
       "      <td>13.947236</td>\n",
       "      <td>7.055340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106762313000</td>\n",
       "      <td>-8.430995</td>\n",
       "      <td>11.413852</td>\n",
       "      <td>5.134871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106872299000</td>\n",
       "      <td>0.953424</td>\n",
       "      <td>1.375655</td>\n",
       "      <td>1.648062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49106982315000</td>\n",
       "      <td>-8.199450</td>\n",
       "      <td>19.572440</td>\n",
       "      <td>2.724070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107092330000</td>\n",
       "      <td>1.416516</td>\n",
       "      <td>5.788648</td>\n",
       "      <td>2.982856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107202316000</td>\n",
       "      <td>-1.879608</td>\n",
       "      <td>-2.982856</td>\n",
       "      <td>-0.299648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107312332000</td>\n",
       "      <td>-6.129157</td>\n",
       "      <td>6.851035</td>\n",
       "      <td>-8.158588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107422348000</td>\n",
       "      <td>5.829509</td>\n",
       "      <td>18.006100</td>\n",
       "      <td>8.539958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107522293000</td>\n",
       "      <td>6.278980</td>\n",
       "      <td>2.982856</td>\n",
       "      <td>2.914754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107632339000</td>\n",
       "      <td>-1.566340</td>\n",
       "      <td>8.308413</td>\n",
       "      <td>-1.457377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107742355000</td>\n",
       "      <td>3.527670</td>\n",
       "      <td>13.593107</td>\n",
       "      <td>9.425281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107852340000</td>\n",
       "      <td>-2.029432</td>\n",
       "      <td>-5.706926</td>\n",
       "      <td>-10.188020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49107962326000</td>\n",
       "      <td>2.764931</td>\n",
       "      <td>10.337844</td>\n",
       "      <td>-9.724928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108062271000</td>\n",
       "      <td>3.568531</td>\n",
       "      <td>13.674830</td>\n",
       "      <td>1.539099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108172348000</td>\n",
       "      <td>-0.503953</td>\n",
       "      <td>3.868179</td>\n",
       "      <td>3.718355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108272262000</td>\n",
       "      <td>-2.301839</td>\n",
       "      <td>1.688923</td>\n",
       "      <td>0.081722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108382370000</td>\n",
       "      <td>-3.568531</td>\n",
       "      <td>19.572440</td>\n",
       "      <td>6.510526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108492294000</td>\n",
       "      <td>-0.803601</td>\n",
       "      <td>-3.296124</td>\n",
       "      <td>-4.630918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108602371000</td>\n",
       "      <td>0.503953</td>\n",
       "      <td>10.841797</td>\n",
       "      <td>13.525005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108702285000</td>\n",
       "      <td>5.706926</td>\n",
       "      <td>15.595298</td>\n",
       "      <td>6.170018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108812332000</td>\n",
       "      <td>-8.662541</td>\n",
       "      <td>7.273266</td>\n",
       "      <td>4.018003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49108922378000</td>\n",
       "      <td>-1.334794</td>\n",
       "      <td>1.225831</td>\n",
       "      <td>2.369940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>33</td>\n",
       "      <td>Jogging</td>\n",
       "      <td>49109022293000</td>\n",
       "      <td>-4.590057</td>\n",
       "      <td>19.572440</td>\n",
       "      <td>4.712640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098174</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622091524000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.270000</td>\n",
       "      <td>2.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098175</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622131471000</td>\n",
       "      <td>8.960000</td>\n",
       "      <td>-1.310000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098176</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622171541000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.330000</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098177</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622211580000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>-1.420000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098178</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622291475000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>-1.380000</td>\n",
       "      <td>2.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098179</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622331483000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.310000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098180</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622371522000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.140000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098181</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622451479000</td>\n",
       "      <td>8.960000</td>\n",
       "      <td>-1.120000</td>\n",
       "      <td>2.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098182</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622491487000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>-1.120000</td>\n",
       "      <td>2.410000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098183</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622531465000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>-1.120000</td>\n",
       "      <td>2.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098184</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622571443000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>-1.140000</td>\n",
       "      <td>2.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098185</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622611635000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.230000</td>\n",
       "      <td>2.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098186</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622691469000</td>\n",
       "      <td>8.920000</td>\n",
       "      <td>-1.230000</td>\n",
       "      <td>2.450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098187</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622731477000</td>\n",
       "      <td>8.770000</td>\n",
       "      <td>-1.330000</td>\n",
       "      <td>2.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098188</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622771486000</td>\n",
       "      <td>8.960000</td>\n",
       "      <td>-1.380000</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098189</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622851472000</td>\n",
       "      <td>8.500000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>2.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098190</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622891511000</td>\n",
       "      <td>8.270000</td>\n",
       "      <td>-1.650000</td>\n",
       "      <td>2.110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098191</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622931490000</td>\n",
       "      <td>8.960000</td>\n",
       "      <td>-1.460000</td>\n",
       "      <td>2.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098192</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131622971498000</td>\n",
       "      <td>9.230000</td>\n",
       "      <td>-1.460000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098193</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623051485000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>-1.230000</td>\n",
       "      <td>2.260000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098194</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623091524000</td>\n",
       "      <td>8.540000</td>\n",
       "      <td>-1.310000</td>\n",
       "      <td>2.490000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098195</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623131471000</td>\n",
       "      <td>8.660000</td>\n",
       "      <td>-1.310000</td>\n",
       "      <td>2.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098196</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623172578000</td>\n",
       "      <td>8.850000</td>\n",
       "      <td>-1.270000</td>\n",
       "      <td>2.180000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098197</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623251466000</td>\n",
       "      <td>9.110000</td>\n",
       "      <td>-1.380000</td>\n",
       "      <td>1.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098198</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623291475000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.500000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098199</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623331483000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.570000</td>\n",
       "      <td>1.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098200</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623371431000</td>\n",
       "      <td>9.040000</td>\n",
       "      <td>-1.460000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098201</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623411592000</td>\n",
       "      <td>9.080000</td>\n",
       "      <td>-1.380000</td>\n",
       "      <td>1.690000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098202</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623491487000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>-1.460000</td>\n",
       "      <td>1.730000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1098203</th>\n",
       "      <td>19</td>\n",
       "      <td>Sitting</td>\n",
       "      <td>131623531465000</td>\n",
       "      <td>8.880000</td>\n",
       "      <td>-1.330000</td>\n",
       "      <td>1.610000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1098204 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user activity        timestamp    x-axis     y-axis     z-axis\n",
       "0          33  Jogging   49105962326000 -0.694638  12.680544   0.503953\n",
       "1          33  Jogging   49106062271000  5.012288  11.264028   0.953424\n",
       "2          33  Jogging   49106112167000  4.903325  10.882658  -0.081722\n",
       "3          33  Jogging   49106222305000 -0.612916  18.496431   3.023717\n",
       "4          33  Jogging   49106332290000 -1.184970  12.108489   7.205164\n",
       "5          33  Jogging   49106442306000  1.375655  -2.492524  -6.510526\n",
       "6          33  Jogging   49106542312000 -0.612916  10.569390   5.706926\n",
       "7          33  Jogging   49106652389000 -0.503953  13.947236   7.055340\n",
       "8          33  Jogging   49106762313000 -8.430995  11.413852   5.134871\n",
       "9          33  Jogging   49106872299000  0.953424   1.375655   1.648062\n",
       "10         33  Jogging   49106982315000 -8.199450  19.572440   2.724070\n",
       "11         33  Jogging   49107092330000  1.416516   5.788648   2.982856\n",
       "12         33  Jogging   49107202316000 -1.879608  -2.982856  -0.299648\n",
       "13         33  Jogging   49107312332000 -6.129157   6.851035  -8.158588\n",
       "14         33  Jogging   49107422348000  5.829509  18.006100   8.539958\n",
       "15         33  Jogging   49107522293000  6.278980   2.982856   2.914754\n",
       "16         33  Jogging   49107632339000 -1.566340   8.308413  -1.457377\n",
       "17         33  Jogging   49107742355000  3.527670  13.593107   9.425281\n",
       "18         33  Jogging   49107852340000 -2.029432  -5.706926 -10.188020\n",
       "19         33  Jogging   49107962326000  2.764931  10.337844  -9.724928\n",
       "20         33  Jogging   49108062271000  3.568531  13.674830   1.539099\n",
       "21         33  Jogging   49108172348000 -0.503953   3.868179   3.718355\n",
       "22         33  Jogging   49108272262000 -2.301839   1.688923   0.081722\n",
       "23         33  Jogging   49108382370000 -3.568531  19.572440   6.510526\n",
       "24         33  Jogging   49108492294000 -0.803601  -3.296124  -4.630918\n",
       "25         33  Jogging   49108602371000  0.503953  10.841797  13.525005\n",
       "26         33  Jogging   49108702285000  5.706926  15.595298   6.170018\n",
       "27         33  Jogging   49108812332000 -8.662541   7.273266   4.018003\n",
       "28         33  Jogging   49108922378000 -1.334794   1.225831   2.369940\n",
       "29         33  Jogging   49109022293000 -4.590057  19.572440   4.712640\n",
       "...       ...      ...              ...       ...        ...        ...\n",
       "1098174    19  Sitting  131622091524000  8.920000  -1.270000   2.220000\n",
       "1098175    19  Sitting  131622131471000  8.960000  -1.310000   2.260000\n",
       "1098176    19  Sitting  131622171541000  8.920000  -1.330000   2.180000\n",
       "1098177    19  Sitting  131622211580000  8.850000  -1.420000   2.260000\n",
       "1098178    19  Sitting  131622291475000  8.880000  -1.380000   2.410000\n",
       "1098179    19  Sitting  131622331483000  8.920000  -1.310000   2.300000\n",
       "1098180    19  Sitting  131622371522000  8.920000  -1.140000   2.260000\n",
       "1098181    19  Sitting  131622451479000  8.960000  -1.120000   2.340000\n",
       "1098182    19  Sitting  131622491487000  9.040000  -1.120000   2.410000\n",
       "1098183    19  Sitting  131622531465000  8.880000  -1.120000   2.370000\n",
       "1098184    19  Sitting  131622571443000  8.880000  -1.140000   2.370000\n",
       "1098185    19  Sitting  131622611635000  8.920000  -1.230000   2.450000\n",
       "1098186    19  Sitting  131622691469000  8.920000  -1.230000   2.450000\n",
       "1098187    19  Sitting  131622731477000  8.770000  -1.330000   2.530000\n",
       "1098188    19  Sitting  131622771486000  8.960000  -1.380000   2.600000\n",
       "1098189    19  Sitting  131622851472000  8.500000  -1.500000   2.560000\n",
       "1098190    19  Sitting  131622891511000  8.270000  -1.650000   2.110000\n",
       "1098191    19  Sitting  131622931490000  8.960000  -1.460000   2.300000\n",
       "1098192    19  Sitting  131622971498000  9.230000  -1.460000   2.260000\n",
       "1098193    19  Sitting  131623051485000  8.850000  -1.230000   2.260000\n",
       "1098194    19  Sitting  131623091524000  8.540000  -1.310000   2.490000\n",
       "1098195    19  Sitting  131623131471000  8.660000  -1.310000   2.370000\n",
       "1098196    19  Sitting  131623172578000  8.850000  -1.270000   2.180000\n",
       "1098197    19  Sitting  131623251466000  9.110000  -1.380000   1.950000\n",
       "1098198    19  Sitting  131623291475000  9.000000  -1.500000   1.800000\n",
       "1098199    19  Sitting  131623331483000  9.000000  -1.570000   1.690000\n",
       "1098200    19  Sitting  131623371431000  9.040000  -1.460000   1.730000\n",
       "1098201    19  Sitting  131623411592000  9.080000  -1.380000   1.690000\n",
       "1098202    19  Sitting  131623491487000  9.000000  -1.460000   1.730000\n",
       "1098203    19  Sitting  131623531465000  8.880000  -1.330000   1.610000\n",
       "\n",
       "[1098204 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['user','activity','timestamp', 'x-axis', 'y-axis', 'z-axis']\n",
    "df = pd.read_csv(path_dataset, header = None, names = columns )\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df[df.activity != 'Jogging']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.activity != 'Downstairs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values in each column:\n",
      "user         0\n",
      "activity     0\n",
      "timestamp    0\n",
      "x-axis       0\n",
      "y-axis       0\n",
      "z-axis       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "null_counts = df.isnull().sum()\n",
    "print(\"Number of null values in each column:\\n{}\".format(null_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "597        Walking\n",
      "598        Walking\n",
      "599        Walking\n",
      "600        Walking\n",
      "601        Walking\n",
      "602        Walking\n",
      "603        Walking\n",
      "604        Walking\n",
      "605        Walking\n",
      "606        Walking\n",
      "607        Walking\n",
      "608        Walking\n",
      "609        Walking\n",
      "610        Walking\n",
      "611        Walking\n",
      "612        Walking\n",
      "613        Walking\n",
      "614        Walking\n",
      "615        Walking\n",
      "616        Walking\n",
      "617        Walking\n",
      "618        Walking\n",
      "619        Walking\n",
      "620        Walking\n",
      "621        Walking\n",
      "622        Walking\n",
      "623        Walking\n",
      "624        Walking\n",
      "625        Walking\n",
      "626        Walking\n",
      "            ...   \n",
      "1098174    Sitting\n",
      "1098175    Sitting\n",
      "1098176    Sitting\n",
      "1098177    Sitting\n",
      "1098178    Sitting\n",
      "1098179    Sitting\n",
      "1098180    Sitting\n",
      "1098181    Sitting\n",
      "1098182    Sitting\n",
      "1098183    Sitting\n",
      "1098184    Sitting\n",
      "1098185    Sitting\n",
      "1098186    Sitting\n",
      "1098187    Sitting\n",
      "1098188    Sitting\n",
      "1098189    Sitting\n",
      "1098190    Sitting\n",
      "1098191    Sitting\n",
      "1098192    Sitting\n",
      "1098193    Sitting\n",
      "1098194    Sitting\n",
      "1098195    Sitting\n",
      "1098196    Sitting\n",
      "1098197    Sitting\n",
      "1098198    Sitting\n",
      "1098199    Sitting\n",
      "1098200    Sitting\n",
      "1098201    Sitting\n",
      "1098202    Sitting\n",
      "1098203    Sitting\n",
      "Name: activity, Length: 655601, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['activity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fifamd\\Anaconda3\\envs\\tf\\lib\\site-packages\\scipy\\stats\\stats.py:253: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "N_TIME_STEPS = 60\n",
    "N_FEATURES = 3\n",
    "step = 124\n",
    "segments = []\n",
    "labels = []\n",
    "for i in range(0, len(df) - N_TIME_STEPS, step):\n",
    "    xs = df['x-axis'].values[i: i + N_TIME_STEPS]\n",
    "    ys = df['y-axis'].values[i: i + N_TIME_STEPS]\n",
    "    zs = df['z-axis'].values[i: i + N_TIME_STEPS]\n",
    "    label = stats.mode(df['activity'][i: i + N_TIME_STEPS])[0][0]\n",
    "    segments.append([xs, ys, zs])\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, N_TIME_STEPS, N_FEATURES)\n",
    "labels = np.asarray(pd.get_dummies(labels), dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reshaped_segments, labels, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5287\n"
     ]
    }
   ],
   "source": [
    "print(len(segments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense,LSTM\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.pooling import MaxPooling1D\n",
    "from keras import optimizers \n",
    "from keras import regularizers\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f1_score_metric(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, \"int32\")\n",
    "    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n",
    "    y_correct = y_true * y_pred\n",
    "    sum_true = tf.reduce_sum(y_true, axis=1)\n",
    "    sum_pred = tf.reduce_sum(y_pred, axis=1)\n",
    "    sum_correct = tf.reduce_sum(y_correct, axis=1)\n",
    "    precision = sum_correct / sum_pred\n",
    "    recall = sum_correct / sum_true\n",
    "    f_score = 5 * precision * recall / (4 * precision + recall)\n",
    "    f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n",
    "    return tf.reduce_mean(f_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4229, 60, 3)\n",
      "(4229, 4)\n",
      "(5287, 60, 3)\n",
      "60 3\n",
      "[[ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  1.]\n",
      " ..., \n",
      " [ 0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(reshaped_segments.shape)\n",
    "numOfRows = reshaped_segments.shape[1]\n",
    "numOfColumns = reshaped_segments.shape[2]\n",
    "filters = 128\n",
    "Epochs = 30\n",
    "batchSize = 10\n",
    "num_class = 4\n",
    "print(numOfRows , numOfColumns)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#y_train = np.reshape(y_train,(527112,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TCNN():\n",
    "    base_model1 = Input(shape=(numOfRows,numOfColumns))\n",
    "    base_model = Conv1D(filters,(11),activation = 'relu')(base_model1)\n",
    "    base_model = MaxPooling1D(pool_size=2)(base_model)\n",
    "    base_model = Conv1D(filters,(11), activation = 'relu')(base_model)\n",
    "    base_model = MaxPooling1D(pool_size=2)(base_model)\n",
    "\n",
    "    base_model = LSTM(128)(base_model)\n",
    "\n",
    "    base_model = Dense(256)(base_model)\n",
    "    base_model = Dropout(0.2)(base_model)\n",
    "    base_model = Dense(4,activation=\"softmax\")(base_model)\n",
    "    model = Model(inputs=[base_model1], outputs=base_model)\n",
    "    adam = optimizers.Adam(lr = 0.001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 3)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 50, 128)           4352      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 15, 128)           180352    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 350,340\n",
      "Trainable params: 350,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "4229/4229 [==============================] - 7s 2ms/step - loss: 0.4248 - acc: 0.8338\n",
      "Epoch 2/30\n",
      " 160/4229 [>.............................] - ETA: 4s - loss: 0.2243 - acc: 0.9187"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fifamd\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:406: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n",
      "C:\\Users\\fifamd\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:497: RuntimeWarning: Early stopping conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n",
      "C:\\Users\\fifamd\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\callbacks.py:898: RuntimeWarning: Reduce LR on plateau conditioned on metric `val_acc` which is not available. Available metrics are: loss,acc,lr\n",
      "  (self.monitor, ','.join(list(logs.keys()))), RuntimeWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4229/4229 [==============================] - 5s 1ms/step - loss: 0.2209 - acc: 0.9182\n",
      "Epoch 3/30\n",
      "4229/4229 [==============================] - 5s 1ms/step - loss: 0.1625 - acc: 0.9404A: 0s - loss: 0.1626 - acc: 0.940\n",
      "Epoch 4/30\n",
      "4229/4229 [==============================] - 5s 1ms/step - loss: 0.1371 - acc: 0.9541\n",
      "Epoch 5/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.1113 - acc: 0.9622\n",
      "Epoch 6/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.1009 - acc: 0.9645\n",
      "Epoch 7/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0787 - acc: 0.9738\n",
      "Epoch 8/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0490 - acc: 0.9830A: 1s - los\n",
      "Epoch 9/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0461 - acc: 0.9844\n",
      "Epoch 10/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0315 - acc: 0.9903\n",
      "Epoch 11/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0466 - acc: 0.9813\n",
      "Epoch 12/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0416 - acc: 0.9872\n",
      "Epoch 13/30\n",
      "4229/4229 [==============================] - 5s 1ms/step - loss: 0.0205 - acc: 0.9936\n",
      "Epoch 14/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0334 - acc: 0.9882\n",
      "Epoch 15/30\n",
      "4229/4229 [==============================] - 4s 950us/step - loss: 0.0331 - acc: 0.9891\n",
      "Epoch 16/30\n",
      "4229/4229 [==============================] - 4s 998us/step - loss: 0.0094 - acc: 0.9972\n",
      "Epoch 17/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 18/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0045 - acc: 0.9983\n",
      "Epoch 19/30\n",
      "4229/4229 [==============================] - 5s 1ms/step - loss: 0.0031 - acc: 0.9993\n",
      "Epoch 20/30\n",
      "4229/4229 [==============================] - 5s 1ms/step - loss: 0.0058 - acc: 0.9981\n",
      "Epoch 21/30\n",
      "4229/4229 [==============================] - 5s 1ms/step - loss: 0.0050 - acc: 0.9986\n",
      "Epoch 22/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0028 - acc: 0.9991\n",
      "Epoch 23/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0012 - acc: 0.9998\n",
      "Epoch 24/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0693 - acc: 0.9780\n",
      "Epoch 25/30\n",
      "4229/4229 [==============================] - 4s 1ms/step - loss: 0.0604 - acc: 0.9790\n",
      "Epoch 26/30\n",
      "4229/4229 [==============================] - 4s 974us/step - loss: 0.0406 - acc: 0.9865\n",
      "Epoch 27/30\n",
      "4229/4229 [==============================] - 4s 992us/step - loss: 0.0112 - acc: 0.9960\n",
      "Epoch 28/30\n",
      "4229/4229 [==============================] - 4s 965us/step - loss: 0.0037 - acc: 0.9995\n",
      "Epoch 29/30\n",
      "4229/4229 [==============================] - 4s 952us/step - loss: 0.0057 - acc: 0.9979\n",
      "Epoch 30/30\n",
      "4229/4229 [==============================] - 4s 963us/step - loss: 0.0096 - acc: 0.9967\n"
     ]
    }
   ],
   "source": [
    "m = TCNN()\n",
    "m.summary()\n",
    "\n",
    "# Callbacks\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
    "                                verbose=1, cooldown=5, min_lr=0)\n",
    "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=20, verbose=0, mode='max')\n",
    "\n",
    "model_1_path = \"./model/model_1/{}.h5\".format(\"model_1\")\n",
    "checkpoint = ModelCheckpoint(model_1_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
    "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
    "\n",
    "history = m.fit(X_train,y_train, epochs = Epochs, callbacks=callbacks_list, verbose =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREREOkSJREREOuT/AxFoy6vIld7jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m.save_weights(\"./model/model_1.6.h5\")\n",
    "m.save(\"./model/Arc_model_1.4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(m.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 1001's data\n",
      "Loading 1002's data\n",
      "Loading 1003's data\n",
      "Loading 1004's data\n",
      "Loading 1005's data\n",
      "Loading 1006's data\n",
      "Loading 1007's data\n",
      "Loading 1008's data\n",
      "Loading 1009's data\n",
      "Loading 1010's data\n",
      "Loading 1011's data\n",
      "Loading 1012's data\n",
      "Loading 2001's data\n",
      "Loading 2002's data\n",
      "Finished loading\n"
     ]
    }
   ],
   "source": [
    "%run load_dataset.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run preprocess_for_SVM.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subj_train = ['1001','1002','1003','1004','2001']\n",
    "subj_val = ['1005','1006','2002']\n",
    "subj_test = ['1007','1008','1009']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_X_y(subj_ids, X, y, s):\n",
    "    X_get = []\n",
    "    y_get = []\n",
    "    s_get = []\n",
    "    for i in range(len(s)):\n",
    "        for j in range(len(subj_ids)):\n",
    "            if(s[i]==subj_ids[j]):\n",
    "                X_get.append(X[i])\n",
    "                y_get.append(y[i])\n",
    "                s_get.append(s[i])\n",
    "                \n",
    "    return np.array(X_get), np.array(y_get), np.array(s_get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, y_train, s_train = get_X_y(subj_train, X_all, y_all, subj_all)\n",
    "X_val, y_val, s_val = get_X_y(subj_val, X_all, y_all, subj_all)\n",
    "X_test, y_test, s_test = get_X_y(subj_test, X_all, y_all, subj_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_pure(X, y, subj_all, new_label_list):\n",
    "    X_label, y_label = label_grouping(X, y, subj_all, new_label_list)\n",
    "    \n",
    "    X_concat = []\n",
    "    y_concat = []\n",
    "    for i in range(len(X_label)):\n",
    "        for j in range(len(X_label[i])):\n",
    "            X_ol, y_ol = make_overlapping(np.array(X_label[i][j]), y_label[i][j])\n",
    "#             print(i, j, X_ol.shape)\n",
    "            \n",
    "            if(len(X_concat)==0):\n",
    "                X_concat = X_ol\n",
    "            else:\n",
    "                X_concat = np.vstack((X_concat, X_ol))\n",
    "\n",
    "            if(len(y_concat)==0):\n",
    "                y_concat = y_ol\n",
    "            else:\n",
    "                y_concat = np.hstack((y_concat, y_ol))\n",
    "                \n",
    "#     X_concat_xyz = concat_xyz(X_concat)\n",
    "    \n",
    "    return X_concat, y_concat    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_label, y_label = label_grouping(X_train, y_train, s_train, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10042, 3) (10042,) (10042,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,s_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_list = [0,1,2,3]\n",
    "label_dict = {\n",
    "    0: 'sit',\n",
    "    1: 'sleep',\n",
    "    2: 'stand',\n",
    "    3: 'walk'\n",
    "}\n",
    "\n",
    "all_subjects = subj_train\n",
    "X_train_pure, y_train_pure = prepare_pure(X_train, y_train, s_train, label_list)\n",
    "\n",
    "all_subjects = subj_val\n",
    "X_val_pure, y_val_pure = prepare_pure(X_val, y_val, s_val, label_list)\n",
    "\n",
    "\n",
    "all_subjects = subj_test\n",
    "X_test_pure, y_test_pure = prepare_pure(X_test, y_test, s_test, label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5275\n"
     ]
    }
   ],
   "source": [
    "VAL_LEN = X_val_pure.shape[0]\n",
    "X_train_pure = X_train_pure[:VAL_LEN]\n",
    "y_train_pure = y_train_pure[:VAL_LEN]\n",
    "\n",
    "print(VAL_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABEL_COUNT = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_y(y, window_length=60):\n",
    "    \n",
    "    y_rs_ = label_binarize(y, classes=[0,1,2,3])\n",
    "    \n",
    "    y_rs = []\n",
    "    for i in range(len(y_rs_)):\n",
    "        y_temp = []\n",
    "        for j in range(window_length):\n",
    "            y_temp.append(y_rs_[i])\n",
    "            \n",
    "        y_rs.append(np.array(y_temp))\n",
    "        \n",
    "    y_rs = np.array(y_rs)\n",
    "    y_rs = y_rs.reshape((y_rs.shape[0],y_rs.shape[1],LABEL_COUNT))\n",
    "        \n",
    "    return np.array(y_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reshape_X(X):\n",
    "    X_rs = X.reshape((X.shape[0],1,X.shape[1]))\n",
    "    return X_rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Y_train = np_utils.to_categorical(y_train, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_rs = reshape_y(y_train_pure)\n",
    "y_val_rs = reshape_y(y_val_pure)\n",
    "y_test_rs = reshape_y(y_test_pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5275, 60, 3)\n",
      "60\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(X_train_pure.shape)\n",
    "print(X_train_pure.shape[1])\n",
    "print(X_train_pure.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run RNN_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model(\"./model/Arc_model_1.4.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_model = create_rnn_model(X_train_pure)\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm = cnn_model(X_train_pure)\n",
    "lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnn_model.load_weights(\"./model/model_1.2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compile_model(model)\n",
    "train_model(model, X_train_pure, y_train_rs, \n",
    "                        X_val_pure, y_val_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr = 0.001, decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 60, 3)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 50, 128)           4352      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 25, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 15, 128)           180352    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 7, 128)            0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 4)                 1028      \n",
      "=================================================================\n",
      "Total params: 350,340\n",
      "Trainable params: 350,340\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_2 to have 2 dimensions, but got array with shape (5275, 60, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-642abeaf4d0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mcallbacks_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mearly_stopper\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreduce_lr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_rs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_pure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val_rs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1591\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1592\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1593\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1594\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1595\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[0;32m   1428\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1429\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1430\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1431\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1432\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tf\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    108\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    111\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_2 to have 2 dimensions, but got array with shape (5275, 60, 4)"
     ]
    }
   ],
   "source": [
    "reduce_lr = ReduceLROnPlateau(monitor='val_acc', mode='max', factor=0.1, patience=10,\n",
    "                                verbose=1, cooldown=5, min_lr=0)\n",
    "early_stopper = EarlyStopping(monitor='val_acc', min_delta=0, \n",
    "                           patience=20, verbose=0, mode='max')\n",
    "\n",
    "model_1_path = \"./model/model_1/{}.h5\".format(\"model_1\")\n",
    "checkpoint = ModelCheckpoint(model_1_path, monitor='val_acc', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n",
    "callbacks_list = [checkpoint,early_stopper,reduce_lr]\n",
    "\n",
    "history = model.fit(X_train_pure, y_train_rs, epochs = 20,  callbacks=callbacks_list, verbose =1 , validation_data=(X_val_pure, y_val_rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = get_y_predict(rnn_model, X_test_pure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_y(y):\n",
    "    y_conv = [j for i in range(len(y)) for j in range(len(y[i][0])) if y[i][0][j]==np.amax(y[i][0])]\n",
    "    return np.array(y_conv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_t = convert_y(y_test_rs)\n",
    "y_p = convert_y(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run eval_score.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LABELS = list(label_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_conf_matrix(y_t, y_p, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "show_clf_report(y_t, y_p, LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# score = history.evaluate(X_test,y_test,verbose=2)\n",
    "print('Baseline Error: %.2f%%' %(100-score[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
